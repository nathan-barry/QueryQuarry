<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QueryQuarry</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <h1>About</h1>
        <span>
            <a href="https://github.com/nathan-barry/QueryQuarry">Github</a>
            <span class="link-separator">|</span>
            <a href="/">Back</a>
        </span>

        <br>
        <br>
        <p>This tool was made by Nathan Barry, a CS and Math undergraduate student at UT Austin, while working at <a href="https://www.arlut.utexas.edu/">Applied Research Laboratories</a>, a UT Austin affiliated research center.</p>

        <br>
        <h2>Why This Project?</h2>
        <p>Data contamination is a large issue in the current LLM space. In the paper <a href="https://aclanthology.org/2023.trustnlp-1.5/">Can we trust the evaluation on ChatGPT?</a>, the authors beg the question: </p>

        <p><i>"Given that ChatGPT is a closed model without [publicly available] information about its training dataset and how it is currently being trained, there is a large loxodonta mammal in the room: how can we know whether ChatGPT has not been contaminated with the evaluation datasets?"</i></p>

        <p>This question affects every NLP researcher and was a problem I ran into time and time again when doing my own evaluations.</p>

        <p>The papers <a href="https://arxiv.org/abs/2310.20707">What's in My Big Data?</a> (AI2) and <a href="https://arxiv.org/abs/2311.17035">Scalable Extraction of Training Data from (Production) Language Models</a> (Google Research) both constructed data structures on large corpa that allowed for efficient exact string lookup. Both papers required Google Cloud compute nodes with (882GB RAM, 224 CPUs) and (1.4TB RAM, 176 CPUs) respectively, expensive hardware that is out of reach for most researchers.</p>

        <p>While the AI2 paper allows access to their search functionality, it is restricted due to the expensive nature of ElasticSearch and the Inverted Index data structure they used which, while more flexible, requires high memory and many cores to do search efficiently. The Google Research paper used Suffix Arrays which perform the lookup using binary search, which is a sequential algorithm and thus does not require much RAM to perform.</p>

        <p>The Google Research paper used code from a previous Google Research paper, <a href="https://arxiv.org/abs/2107.06499">Deduplicating Training Data Makes Language Models Better</a>, to construct the Suffix Array. While this implementation does construct it using external memory, it does have the requirement that the initial dataset can fit into memory, thus still requiring expensive machines to construct the data structures.</p>

        <p>This project aims to host search functionality on a variety of popular large datasets. We use the aforementioned <a href="https://github.com/google-research/deduplicate-text-datasets">Google Research repository</a> to construct these large data structures on any HuggingFace dataset. This project implements a more efficient Count Occurrences implementation that runs roughly 500-1000x faster than the original implementation. We provide a workflow that allows one to easily download a dataset, pre-process it, construct a suffix array, and host a service that allows one to query it. We provide a front-end for easy interaction and a CLI that can retrieve every document in a dataset where a query occurs.</p>
    </div>
</body>
</html>
